{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPoyhH3bjubGsaCxl2Ro3/8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riddick4-droid/Machine_Learning-Pt/blob/main/Stock_Prediction_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STOCK PRICE PREDICTION WITH DIFFERENT ALGORITHMS"
      ],
      "metadata": {
        "id": "xnr0qXW0VB-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook I explore the use of rhree different regression algorithms for predicting stock prices. I will evaluate the models with known regression metrics such as `MEAN SQUARED ERROR` or `ROOT MEAN SQUARED ERROR` , the `MEAN ABSOLUTE ERROR` and the `R_SQUARED`. The models i will explore include:\n",
        "1. Linear regression\n",
        "2. SGD Regressor\n",
        "3. Regression Forest\n",
        "4. Neural Network-from Tensorflow"
      ],
      "metadata": {
        "id": "JGjdBs1cVNrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dependencies\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import LinearRegression,SGDRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeRegressor,plot_tree\n",
        "import kagglehub\n",
        "import os"
      ],
      "metadata": {
        "id": "DI5RDKwiVNgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##load data from kagglehub api\n",
        "path = kagglehub.dataset_download(\"jacksoncrow/stock-market-dataset\")\n",
        "\n",
        "#print path\n",
        "print(f'path to dataset is {path}')"
      ],
      "metadata": {
        "id": "SaP84NvwVNdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(path)"
      ],
      "metadata": {
        "id": "outlIat25Y_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(os.path.join(path,'symbols_valid_meta.csv')).head(20)"
      ],
      "metadata": {
        "id": "nz033_6L5d5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets check the file in the path directory\n",
        "os.listdir(os.path.join(path,'stocks'))[:20]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dBpkdhAdXmng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##lets select one stock\n",
        "##selecting 'CEI.csv'\n",
        "new_path = os.path.join(path,'stocks')"
      ],
      "metadata": {
        "id": "Zg5I0MBCY0eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##lets load it as a csv with pandas\n",
        "data = pd.read_csv(os.path.join(new_path,'AAPL.csv')).set_index('Date')\n",
        "\n",
        "#display\n",
        "display(data.head())"
      ],
      "metadata": {
        "id": "MCv4KmI_Xeky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##check the last date\n",
        "display(data.tail(30))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TfSBJotTbpEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##checking the data shape\n",
        "print(f'There are {data.shape[0]} instances and {data.shape[1]} features')"
      ],
      "metadata": {
        "id": "6eVVrCFfZY34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##explore the data\n",
        "matplotlib.rcParams['figure.figsize']=(12,5)\n",
        "plt.plot(data['Close'][:1000],label='close')\n",
        "plt.plot(data['Open'][:1000],label='open')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Open and Close')\n",
        "plt.legend(loc='upper right');"
      ],
      "metadata": {
        "id": "JfmtA9xgZ5UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stocks are auto regressive(or have temporal dependencies) in nature,where a price at a time may depend on\n",
        "#one or more previous prices\n",
        "#i will demonstrate a simple function to give us this autoregressive data\n",
        "import typing\n",
        "def generate_autoreg(data,\n",
        "                     cutoff:int=60,\n",
        "                     window:int=60,\n",
        "                     return_df:typing.Literal['test','train']='train'):\n",
        "    #this function handles the autoregressive splitting for timeseries for me\n",
        "    #allows flexible window selection by just plugging in the autoregressive window integer for num days\n",
        "    #returns a dataframe for clear structure understanding: set 'return_df=True' always\n",
        "    train_data = data['Close'].iloc[:-cutoff]\n",
        "\n",
        "    #use the final 30 days data as test data\n",
        "    #ensure that it also autoregressive\n",
        "    test_data = data['Close'].iloc[-cutoff:]\n",
        "\n",
        "\n",
        "    x_train,y_train = [],[] #collects prior days\n",
        "    x_test,y_test = [],[] #collects next day prices\n",
        "\n",
        "    #scale the data\n",
        "    scale = MinMaxScaler()\n",
        "\n",
        "    #scale data and get values then reshape those values\n",
        "    data_scaled_train = scale.fit_transform(train_data.values.reshape(-1,1))\n",
        "\n",
        "    data_scaled_test = scale.transform(test_data.values.reshape(-1,1))\n",
        "\n",
        "    #get for train data\n",
        "    for i in range(window,len(train_data)):\n",
        "        x_train.append(data_scaled_train[i-window:i,0])\n",
        "        y_train.append(np.array(train_data)[i])\n",
        "    #convert to numpy array\n",
        "    x_train,y_train = np.array(x_train),np.array(y_train)\n",
        "\n",
        "    #for test data\n",
        "    for i in range(window,len(test_data)):\n",
        "        x_test.append(data_scaled_test[i-window:i,0])\n",
        "        y_test.append(np.array(test_data)[i])\n",
        "\n",
        "    x_test,y_test = np.array(x_test),np.array(y_test)\n",
        "\n",
        "    #lets use a dataframe\n",
        "    if return_df=='train':\n",
        "        colnames = [f'day_{i}' for i in range(1,window+1)]\n",
        "        days_data_train = pd.DataFrame(x_train,columns=colnames)\n",
        "        days_data_train['next_day_price'] = y_train\n",
        "        return days_data_train\n",
        "\n",
        "    elif return_df == 'test':\n",
        "        colnames = [f'day_{i}' for i in range(1,window+1)]\n",
        "        days_data_test = pd.DataFrame(x_test,columns=colnames)\n",
        "        days_data_test['next_day_price'] = y_test\n",
        "        return days_data_test"
      ],
      "metadata": {
        "id": "t4-NTFOsbGBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##lets test the function\n",
        "days_data_train = generate_autoreg(data=data,\n",
        "                                   cutoff=60,\n",
        "                                   window=20,\n",
        "                                   return_df='train')\n",
        "\n",
        "#display data\n",
        "display(days_data_train.head(10))"
      ],
      "metadata": {
        "id": "N1RDBNZ5e0ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##lets test the function\n",
        "days_data_test = generate_autoreg(data=data,\n",
        "                                   cutoff=60,\n",
        "                                   window=20,\n",
        "                                   return_df='test')\n",
        "\n",
        "#display data\n",
        "display(days_data_test.head(10))"
      ],
      "metadata": {
        "id": "bAWtxxmMLV9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above was an example of a 20 day window that means we will 20 days data always trying to predict the 20 + 1 day price. The 20 days price are scaled and act as our features. The function does well to skip the next day prices and exempt it from being scaled as these values are our targets and in ML we mostly do no scale targets. IN autoregression, specifically stock prices, it is imperative to always have more days data prior so that the model can have enough to learn from in extracting patterns. However, simple machine learning models like linear models i.e regression models in this case due to the target variable being of continuous nature fail to capture long-range dependencies-thus they do not have the ability to remember whats in the past and will suffer to find the underlying patterns unless otherwise they overfit.\n",
        "As such i will experiment with neural networks and find out if they are able to solve the long range and high dimensionality of autoregressive models problem"
      ],
      "metadata": {
        "id": "gMfhRBSa2UFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check days data shape\n",
        "print(f'new autoregressive data has shape {days_data_train.shape}')"
      ],
      "metadata": {
        "id": "BvocOxVWihaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we want to test the models' ability to capture the autoregressive relationship between\n",
        "##the features or prior days and the next day\n",
        "#we use the first train data to train the algorithm to get our model\n",
        "#then test the models ability to predict with unseen data from the test data set"
      ],
      "metadata": {
        "id": "WoTSRKhQihR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "HFoWC1uBnpFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first model is linear regression without SGD\n",
        "#split the data into features and target\n",
        "x_train = days_data_train.drop('next_day_price',axis=1)\n",
        "y_train = days_data_train['next_day_price']\n",
        "\n",
        "#init model\n",
        "lr = LinearRegression(fit_intercept=True,n_jobs=-1) #not much hyperparameters to tune here\n",
        "\n",
        "#fit\n",
        "lr.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "_MWxYNWhnoXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##lets define a funcition to capture all the metrics\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
        "\n",
        "def capture_metrics(test,model):\n",
        "    #this function captures 3 metrics specific to regression at a go\n",
        "    #it captures the model's performance in terms of MSE,MAE and R_sqr\n",
        "    #specifically on the test data\n",
        "    #enables automation and reduces the need to always write the metrics calculation for\n",
        "    #all models tested\n",
        "\n",
        "    x_test = test.drop('next_day_price',axis=1)\n",
        "    y_test = test['next_day_price']\n",
        "\n",
        "    #make prediction\n",
        "    predictions = model.predict(x_test)\n",
        "\n",
        "    #get model performance\n",
        "    mse = mean_squared_error(y_true=y_test,y_pred=predictions)\n",
        "    mae = mean_absolute_error(y_true=y_test,y_pred=predictions)\n",
        "    r_squared = r2_score(y_true=y_test,y_pred=predictions)\n",
        "\n",
        "    #print results\n",
        "    print(f'MSE: {mse} | MAE: {mae} | RSQ: {r_squared}')\n",
        "\n",
        "    #return dataframe\n",
        "    results = {\n",
        "        f'mse_{model.__class__.__name__}':round(mse,4),\n",
        "        f'mae_{model.__class__.__name__}':round(mae,4),\n",
        "        f'rsq_{model.__class__.__name__}':round(r_squared,4)\n",
        "    }\n",
        "\n",
        "    return pd.DataFrame([results]),predictions"
      ],
      "metadata": {
        "id": "aYggXezjps26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###apply on train data\n",
        "results_train,inference_lr_train = capture_metrics(days_data_train,lr)\n",
        "\n",
        "results_train"
      ],
      "metadata": {
        "id": "LDDf2FMDCAiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(inference_lr_train)==len(y_train)"
      ],
      "metadata": {
        "id": "_zbabcJmC0ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##lets visualize the values\n",
        "import typing\n",
        "def plot_model_pred(predictions,data,plot_range:int,figsize:typing.Tuple[int,int],plot_continuation:bool=False):\n",
        "    ##the function plots the actual data trend vs the predicted\n",
        "    ##you can choose to let it plot it side by side or to let it plot as a s continuation of trend\n",
        "\n",
        "    #set figsize\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    if plot_continuation:\n",
        "        x=range(plot_range)\n",
        "        plt.plot(x,predictions[-x[-1]-1:],label='predictions',linestyle='--')\n",
        "        plt.plot(x,data['next_day_price'][-x[-1]-1:],label='actuals')\n",
        "        plt.title('Actual vs Predicted')\n",
        "        plt.ylabel('Index')\n",
        "        plt.xlabel('Value')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    else:\n",
        "        pass"
      ],
      "metadata": {
        "id": "ZZt-fP3f6RJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model_pred(inference_lr_train, days_data_train, 5, (15,5), True)"
      ],
      "metadata": {
        "id": "1LZrUovk8QiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_test,inference_lr = capture_metrics(days_data_test,lr)\n",
        "\n",
        "results_test"
      ],
      "metadata": {
        "id": "Qz_bbadqt179"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(inference_lr)==len(days_data_test['next_day_price'])"
      ],
      "metadata": {
        "id": "_FdFH6NmwVaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##plot test data predictions\n",
        "plot_model_pred(inference_lr, days_data_test, 40, (15,5), True)"
      ],
      "metadata": {
        "id": "TL0GkSzZBo7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SGDRegressor-That is regression with Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "ZcoZ19YRyH3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement the GridSearchCV\n",
        "params = {\n",
        "    'alpha':[1e-4,3e-4,1e-3],\n",
        "    'eta0':[0.01,0.03,0.1]\n",
        "}\n",
        "\n",
        "#init model\n",
        "sgd_lr = SGDRegressor(penalty='l2',max_iter=5000,random_state=42,verbose=1)\n",
        "\n",
        "#implement the cross validation\n",
        "#first perform TimeSeriesSPlit to maintain timeseries structure\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "#grid search\n",
        "grid_search = GridSearchCV(sgd_lr,params,cv=tscv,scoring='r2')\n",
        "\n",
        "#fit\n",
        "grid_search.fit(x_train,y_train)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NuMk2Tnsxv6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##get best params\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "BF1nSskjEmLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##fit the model again with the best parameters\n",
        "sgd_lr = SGDRegressor(penalty='l2',max_iter=5000,random_state=42,verbose=1,alpha=0.0001,eta0=0.1)\n",
        "\n",
        "#fit\n",
        "sgd_lr.fit(x_train,y_train)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OOjmKMBuCeqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##lets compute metrics\n",
        "results_train_sgd,inference_lr_train_sgd = capture_metrics(days_data_train,sgd_lr)\n",
        "\n",
        "results_train_sgd"
      ],
      "metadata": {
        "id": "FK2pULhrDCYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##plot predictions for train data\n",
        "plot_model_pred(inference_lr_train_sgd, days_data_train, 200, (15,5), True)"
      ],
      "metadata": {
        "id": "jM123bnrDPbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "always try to get a granular view of the model performance when plotting the predictions as this will help see whether it is gettting it right. Using a more denser plot will hide the model's performance and will give us the impressinon that it is actually performing well"
      ],
      "metadata": {
        "id": "waeCAx9wDfbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check for the test data\n",
        "results_test_sgd,inference_lr_test_sgd = capture_metrics(days_data_test,sgd_lr)\n",
        "\n",
        "results_test_sgd"
      ],
      "metadata": {
        "id": "YULYsOgED9iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##plot predictions for test data\n",
        "plot_model_pred(inference_lr_test_sgd, days_data_test, 40, (15,5), True)"
      ],
      "metadata": {
        "id": "TdALwZ2-D9gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Trees"
      ],
      "metadata": {
        "id": "upZil0ANEw1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##lets try with dt\n",
        "dt = DecisionTreeRegressor(criterion='squared_error',random_state=42)\n",
        "\n",
        "#setup params\n",
        "param_grid = {'min_samples_split':[2,3],\n",
        "              'max_depth':[25,30],\n",
        "              'min_samples_leaf':[3,4],\n",
        "              'ccp_alpha':[1e-4,3e-4,1e-3],\n",
        "              }\n",
        "#this may take a while :) if no patience, use RandomizedSearchCV\n",
        "grid_search_dt = GridSearchCV(estimator=dt,param_grid=param_grid,cv=tscv,n_jobs=-1,scoring='r2')\n",
        "\n",
        "#fit\n",
        "grid_search_dt.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "BdYA08cjD9eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##best estimator\n",
        "grid_search_dt.best_params_\n",
        "\n",
        "#fit with best params\n",
        "#the '**' before the grid_search_dt helps unpack the values in the dictionary\n",
        "dt = DecisionTreeRegressor(**grid_search_dt.best_params_,random_state=42,criterion='squared_error')\n",
        "\n",
        "#fit\n",
        "dt.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "iL4_PjqYGYrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##check performance and plot\n",
        "results_train_dt,inference_dt_train = capture_metrics(days_data_train,dt)\n",
        "\n",
        "results_train_dt"
      ],
      "metadata": {
        "id": "m8U2WMX9MsjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot for the train\n",
        "plot_model_pred(inference_dt_train, days_data_train, 100, (15,5), True)"
      ],
      "metadata": {
        "id": "1ljC8p9zM8eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##check performance and plot\n",
        "results_test_dt,inference_dt_test = capture_metrics(days_data_test,dt)\n",
        "\n",
        "results_test_dt\n",
        "\n",
        "\n",
        "#plot\n",
        "plot_model_pred(inference_dt_test, days_data_test, 40, (15,5), True)"
      ],
      "metadata": {
        "id": "m37vpjkGGe4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomForestRegressor"
      ],
      "metadata": {
        "id": "ce49MCHSNQTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##parmeters for tuning and cross val\n",
        "param_grid = {\n",
        "    'max_depth':[20,30,50],\n",
        "    'min_samples_split':[2,5,10],\n",
        "    'min_samples_leaf':[1,3,5]\n",
        "}\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=30,n_jobs=-1,random_state=42)\n",
        "\n",
        "grid_search_rf = GridSearchCV(rf,param_grid=param_grid,cv=tscv,scoring='r2',n_jobs=-1,verbose=1)\n",
        "\n",
        "#fit\n",
        "grid_search_rf.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "Fwi6yLxFHKj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##best params\n",
        "grid_search_rf.best_params_,grid_search_rf.best_score_\n",
        "\n",
        "#fit\n",
        "rf_best = RandomForestRegressor(**grid_search_rf.best_params_,n_estimators=30,n_jobs=-1,random_state=42)\n",
        "\n",
        "rf_best.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "KLqhNmARN9SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#capture metrics\n",
        "results_train_rf,inference_rf_train = capture_metrics(days_data_train,rf_best)\n",
        "\n",
        "results_train_rf\n",
        "\n",
        "\n",
        "#plot\n",
        "plot_model_pred(inference_rf_train, days_data_train, 100, (15,5), True)"
      ],
      "metadata": {
        "id": "a-NnO4DOPnu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##test data\n",
        "#capture metrics\n",
        "results_test_rf,inference_rf_test = capture_metrics(days_data_test,rf_best)\n",
        "\n",
        "results_test_rf\n",
        "\n",
        "\n",
        "#plot\n",
        "plot_model_pred(inference_rf_test, days_data_test, 40, (15,5), True)"
      ],
      "metadata": {
        "id": "h810A8fXP_h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##function to plot all\n",
        "all_results_train = {\n",
        "    'truth':days_data_train['next_day_price'].tolist(),\n",
        "    'lr':inference_lr_train.tolist(),\n",
        "    'sgd_lr':inference_lr_train_sgd.tolist(),\n",
        "    'decision_trees':inference_dt_train.tolist(),\n",
        "    'random_forest':inference_rf_train.tolist()\n",
        "}\n",
        "\n",
        "#make dataframe\n",
        "train_perf = pd.DataFrame(all_results_train)\n",
        "\n",
        "train_perf.iloc[-150:].plot();"
      ],
      "metadata": {
        "id": "vtPv-KJzQezQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_results_test = {\n",
        "    'truth':days_data_test['next_day_price'].tolist(),\n",
        "    'lr':inference_lr.tolist(),\n",
        "    'sgd_lr':inference_lr_test_sgd.tolist(),\n",
        "    'decision_trees':inference_dt_test.tolist(),\n",
        "    'random_forest':inference_rf_test.tolist()\n",
        "}\n",
        "\n",
        "#make dataframe\n",
        "test_perf = pd.DataFrame(all_results_test)\n",
        "\n",
        "test_perf.plot();"
      ],
      "metadata": {
        "id": "ouBZq7Q5VTvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final graph displays the actual stock prices (truth) in blue, alongside the predictions from the four different models on the test data: Linear Regression (lr, orange), SGD Regressor (sgd_lr, green), Decision Trees (decision_trees, red), and Random Forest (random_forest, purple).\n",
        "\n",
        "Here's an interpretation of their performance:\n",
        "\n",
        "`Actual Prices (truth)`: The blue line shows the actual stock price movement in the test set, which has a general downward trend with several fluctuations.\n",
        "`Linear Regression (lr)` and `SGD Regressor (sgd_lr)`: Both lr (orange) and sgd_lr (green) appear to follow the general downward trend of the actual prices. However, they tend to be smoother and lag behind the sharper movements and sudden drops in the actual prices. They capture the overall direction but lack the responsiveness to capture rapid changes.\n",
        "`Decision Trees (decision_trees)`: The red line for Decision Trees shows a very poor performance. It predicts constant values for significant periods, indicating a severe lack of generalization. For instance, it predicts around 300 for the first segment, then drops to around 275-280, and then later to around 260. This step-like behavior suggests it has failed to learn the underlying patterns and has likely overfit to the training data, producing flat predictions on unseen data.\n",
        "`Random Forest (random_forest)`: Similar to Decision Trees, the purple line for Random Forest also exhibits a step-like or largely flat prediction for considerable stretches, particularly in the earlier part of the test data (predicting around 290). While it shows some more variation than the single `Decision Tree`, it still struggles to accurately track the dynamic nature of the stock prices in the test set. It too appears to suffer from poor generalization.\n",
        "`Overall Conclusion`: Based on this visualization, both Linear Regression and SGD Regressor models, while imperfect, provide a more reasonable approximation of the stock price trend on the test data compared to the Decision Tree and Random Forest models. The tree-based models perform poorly, indicating they are not well-suited for capturing the continuous and dynamic nature of this time series data, likely due to overfitting during training."
      ],
      "metadata": {
        "id": "OpDbIUWiYsL5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m7NHryC2dl6f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}